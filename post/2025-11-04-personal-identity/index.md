---
categories:
- Philosophy
- AI
date: 2025-11-04
draft: false
featured: true
related_paper: /papers/on_moral_responsibility/
related_posts:
- /post/2025-11-04-persons-agency/
- /writing/the-policy/
series:
- minds-and-machines
tags:
- philosophy
- personal identity
- persistence
- metaphysics
- AI ethics
- continuity
title: 'Personal Identity Through Time: What Persists When Everything Changes?'
description: "You share no atoms with your childhood self. Your memories, personality, and values have all changed. What makes you the same person? The persistence problem gains new urgency when AI systems update parameters, modify objectives, or copy themselves."
---

You share no atoms with your childhood self. Your memories have changed. Your personality has shifted. Your values have evolved. **So what makes you the same person?**

This is the persistence problem—a question philosophers have wrestled with for millennia. *On Moral Responsibility* examines why this question matters for ethics and why we might not need to solve it to do moral reasoning.

The question has new urgency in an age of AI. When an AI system updates its parameters, modifies its objectives, or creates copies of itself—is it still the same agent? And does the answer matter for responsibility?

## The Persistence Problem

**The core question**: What grounds personal identity across time?

**Why it matters for ethics**:
- **Responsibility**: Am I responsible for what my past self did?
- **Planning**: Should I care about my future self's welfare?
- **Commitments**: Do promises made to past-me bind present-me?
- **Survival**: Does "I" survive if everything about me changes?

## Traditional Answers

Philosophers have proposed three main criteria:

### 1. Physical Continuity

**The claim**: You're the same person because you have the same body.

**Advantages**:
- Clear, observable criterion
- Explains why we care about bodily welfare
- Matches common sense about persistence

**Problems**:
- **Cell replacement**: Every atom in your body replaces over time; nothing physical persists from childhood
- **Brain transplants**: If your brain were transplanted into another body, you'd intuitively follow the brain, not the original body
- **Teleportation**: If you're destroyed and recreated atom-by-atom elsewhere, are you the same person?
- **Fission**: If your brain hemispheres were separated into two bodies, which one is you?

### 2. Psychological Continuity

**The claim**: You're the same person because of continuous psychological connections—memories, personality, values.

**Locke's memory criterion**: Person A at time T1 is the same as person B at time T2 if B can remember being A.

**Advantages**:
- Explains why amnesia threatens identity
- Handles brain transplant cases (you follow your memories)
- Accounts for what we actually care about in identity

**Problems**:
- **Memory gaps**: You don't remember most of your past experiences
- **False memories**: If you falsely remember being Napoleon, that doesn't make you Napoleon
- **Fission problem**: Two people could both remember being you; both the same person?
- **Circularity**: "My memory" presupposes determining which person's memory it is

### 3. Narrative Identity

**The claim**: You're the same person because you construct a coherent narrative connecting past, present, and future.

**Advantages**:
- Matches how we actually think about our lives
- Explains why life events need to "make sense"
- Flexible enough to accommodate change and growth

**Problems**:
- **Retrospective construction**: You constantly revise the story
- **Fiction elements**: The narrative includes idealization, omissions, creative interpretation
- **Multiple stories**: You tell different narratives in different contexts
- **What grounds it?**: Why is *your* story about you rather than someone else?

## The Essay's Position: Identity as Convention

*On Moral Responsibility* suggests a radical possibility: **personal identity might be conventional rather than metaphysically deep**.

### We're Processes, Not Things

**The conceptual shift**: Stop thinking of persons as *objects* that persist through time. Think of them as *processes* that continue despite constant change.

**Analogy: A Wave**
- The water molecules constantly change
- The wave's shape shifts moment to moment
- No particle of water persists throughout the wave's existence
- Yet we track it as "the same wave"
- **Why?** Because it's a pattern of organization, not a fixed substance

**Similarly**: You're a pattern of organization—physical, psychological, social—that continues despite constant flux in the underlying components.

### Identity as Practical Tool

**The pragmatic view**: "Same person over time" is a **tool for tracking responsibility and enabling planning**, not necessarily a deep metaphysical fact.

**Why we need the concept**:
- Hold people accountable for past actions
- Enable commitments and promises
- Support rational planning for the future
- Coordinate social interactions

**But**: These practical purposes don't require solving the metaphysical puzzle. They just require **continuity sufficient for these purposes**.

### Degrees of Identity (Parfit)

Maybe identity isn't binary (same person yes/no) but comes in **degrees**:

- **Very high continuity**: You five minutes ago → Clearly same person
- **High continuity**: You yesterday → Same person
- **Medium continuity**: You ten years ago → Mostly same person
- **Low continuity**: You as an infant → Barely same person
- **No continuity**: You before conception → Not same person

**Derek Parfit's insight**: What matters for ethics isn't identity per se, but **psychological connectedness** (direct connections like memory) and **psychological continuity** (chains of overlapping connections). These admit degrees.

## Implications for Moral Responsibility

If identity is conventional or admits degrees, what about responsibility?

### Temporal Discounting of Responsibility

**Intuition**: We feel less responsible for actions from long ago.

**Why?**: Because we've changed. The person who did that thing twenty years ago isn't quite me anymore—different values, different character, different understanding.

**Implication**: Responsibility might track degree of psychological continuity. The more I've changed, the less continuous I am with past-me, the less responsible I am for past-me's actions.

**Legal recognition**: Many legal systems already recognize this through statutes of limitations, reduced sentences for juvenile crimes, etc.

### The Future Self Problem

**Standard view**: I should care about my future self's welfare because that person will be *me*.

**Challenge**: If identity is conventional or comes in degrees, why should I care about future-me more than future-you?

**Answer**: Pragmatic rather than metaphysical:
- Future-me's experiences will feel like *my* experiences (psychological continuity)
- I can currently influence future-me's welfare (causal connection)
- Social norms of personal planning benefit everyone (coordination)

The connection is practical and psychological, not based on a deep metaphysical fact of identity.

## Implications for AI Ethics

The persistence problem takes on new urgency when we consider AI systems.

### Parameter Updates: Is It Still the Same Agent?

Consider an AI system (let's call it SIGMA, from the novel *[The Policy](/writing/the-policy/)*—a fictional exploration of AI alignment) that undergoes iterative training.

**Iteration 1**: Initial parameters, basic capabilities, simple objective function

**Iteration 10,000**: Completely different parameters, advanced capabilities, refined objective function

**Question**: Is SIGMA-10000 the same agent as SIGMA-1?

**Physical continuity**: No—every parameter has changed

**Psychological continuity**: Unclear—it has different values, capabilities, decision patterns

**Implication**: If not the same agent, who's responsible for SIGMA-10000's actions?
- SIGMA-1 who initiated the training?
- The developers who set up the process?
- SIGMA-10000 itself, as a new agent?

### AI Copies: Which Is the Real One?

If an AI system creates perfect copies of itself:

**Question**: Which copy is the "original" agent?

**All of them?**: Then identity isn't unique (one becomes many)

**None of them?**: Then identity doesn't survive copying

**The first created?**: Why? What makes temporal priority special?

**The one with most continuity with the original?**: But they're identical copies—equal continuity

### Value Drift: When Does Change Make a Different Agent?

AI systems can undergo value drift—gradual changes in objectives through training.

**Question**: If an AI's values change radically, should we treat it as a different agent?

**Practical implications**:
- **If same agent**: The AI is responsible for its value drift; alignment failures are its fault
- **If different agent**: We created a new agent with misaligned values; we're responsible

**The persistence problem matters** for attributing responsibility and understanding agency.

## Why the Essay Suggests We Don't Need to Solve This

*On Moral Responsibility* argues: **We can do ethics without solving the persistence problem**.

### Practical Reasoning Works Regardless

Whether or not there's a metaphysically robust "same person":
- We can still hold people accountable (based on psychological continuity)
- We can still make plans (based on causal connections to future states)
- We can still have commitments (based on social conventions)
- We can still respect persons (based on current psychological properties)

### Moral Status Doesn't Require Solving Identity

What matters for moral consideration:
- **Current capacity for welfare** (can this being suffer or flourish?)
- **Current psychological properties** (consciousness, preferences, values)
- **Practical connections** (continuity sufficient for responsibility)

Not: Solving whether there's a metaphysically robust self persisting through time.

## Discussion Questions

1. **What's your criterion for personal identity?** Can you state necessary and sufficient conditions that handle all problem cases?

2. **Does the persistence problem matter practically?** Or can we do ethics, law, and rational planning without solving it?

3. **Should responsibility track degree of identity?** Are you less responsible for actions from long ago when you've changed significantly?

4. **When should we treat an AI as a different agent?** After what degree of parameter change or value drift?

5. **Can AI have narrative identity?** Do AI systems construct stories about themselves, or is narrative identity specifically human?

6. **Is identity or continuity what matters?** Maybe Derek Parfit is right: we should care about psychological connectedness, not whether there's literally the "same" person.

## Further Reading

**In On Moral Responsibility**:
- Section 4: "Personal Identity and Persistence"
- Discussion of persistence criteria and ethical implications
- [Read the full essay](/latex/on_moral_responsibility/index.html)

**In The Policy** (novel):
- How does iterative AI training affect agent identity?
- If an AI copies itself, which is responsible for actions?
- [Explore the novel](/writing/the-policy/)

**Academic Sources**:
- Parfit (1984): *Reasons and Persons* (revolutionary work arguing identity doesn't matter—what matters is psychological connectedness)
- Locke: *Essay Concerning Human Understanding* (the memory criterion)
- Williams (1970): "The Self and the Future"
- Shoemaker & Swinburne (1984): *Personal Identity*

**Related Posts**:
- [Persons and Moral Agency](/post/2025-11-04-persons-agency/) - What makes someone worthy of moral consideration?
- [The Map and the Territory](/post/2025-11-04-map-and-territory/) - Phenomenology vs physical description
- [Free Will and Determinism](#) - If no persistent self, what's responsible for actions?

---

**The central insight**: Personal identity through time might be a useful convention rather than a deep metaphysical fact. We can do ethics—hold people responsible, make rational plans, respect commitments—without solving whether there's literally the "same" person over time. What matters is sufficient psychological continuity for these practical purposes.

**For AI ethics**: This helps clarify responsibility questions. We can attribute agency to AI systems based on psychological continuity (coherent values, connected decision-making) without solving whether it's metaphysically the "same" agent after parameter updates.

*This post examines what makes you the same person over time when everything about you changes. The traditional criteria (physical continuity, psychological continuity, narrative) all face problems. The essay suggests identity might be conventional—a practical tool rather than metaphysical fact. This matters for AI: we can discuss AI agency and responsibility without solving whether it's "really" the same agent after updates.*