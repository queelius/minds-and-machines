# About

AI alignment, moral agency, superintelligence, and the futures we might build.

## Author

**Alex Towell**

- Blog: [metafunctor.com](https://metafunctor.com)
- GitHub: [github.com/queelius](https://github.com/queelius)
- Email: [queelius@gmail.com](mailto:queelius@gmail.com)

## Repository

Source: [github.com/queelius/minds-and-machines](https://github.com/queelius/minds-and-machines)

## Key Themes

- What happens when we build minds we can't understand?
- Intelligence as optimization under uncertainty
- The alignment problem: ensuring optimization serves human values
- Fiction as a vehicle for exploring abstract risks
- Philosophical foundations: personhood, agency, values, identity

## License

MIT
